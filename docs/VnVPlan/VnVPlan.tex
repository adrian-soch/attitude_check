\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{enumitem,amssymb}
\usepackage{amsmath, mathtools}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{float}
\usepackage{pdflscape}
\hypersetup{ colorlinks, citecolor=blue, filecolor=cyan, linkcolor=red, urlcolor=blue }
\usepackage[round]{natbib}

\input{../Comments}
\input{../Common}

\newlist{todolist}{itemize}{2}
\setlist[todolist]{label=$\square$}

\newcommand{\testref}[1]{T\ref{#1}} \newcounter{testnum}
\newcommand{\Tthetestnum}{T\thetestnum}

\newcommand{\utestref}[1]{UT\ref{#1}} \newcounter{utestnum}
\newcommand{\UTthetestnum}{UT\theutestnum}

\begin{document}

\title{System Verification and Validation Plan for \progname{}}
\author{\authname}
\date{\today}

\maketitle

\pagenumbering{roman}

\section*{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X} \toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
2024/02/13 & 1.0 & Initial draft\\
\bottomrule
\end{tabularx}

~\\
\wss{The intention of the VnV plan is to increase confidence in the software. However, this does not
mean listing every verification and validation technique that has ever been devised.  The VnV plan
should also be a \textbf{feasible} plan. Execution of the plan should be possible with the time and
team available. If the full plan cannot be completed during the time available, it can either be
modified to ``fake it'', or a better solution is to add a section describing what work has been
completed and what work is still planned for the future.}

\wss{The VnV plan is typically started after the requirements stage, but before the design stage.
This means that the sections related to unit testing cannot initially be completed.  The sections
will be filled in after the design stage is complete.  the final version of the VnV plan should have
all sections filled in.}

\newpage

\tableofcontents

\listoftables
\wss{Remove this section if it isn't needed}

\listoffigures
\wss{Remove this section if it isn't needed}

\newpage

\section{Symbols, Abbreviations, and Acronyms}

For symbols and units see the Section 1 of the SRS \citep{SRS}. Table \ref{tab:abb} defines the
abbreviations and acronyms used in this document.

% \renewcommand{\arraystretch}{1.2} \begin{tabular}{l l} \toprule \textbf{symbol} &
%   \textbf{description}\\
%   \midrule T & Test\\
%   \bottomrule \end{tabular}\\

\begin{table}[!h]
  \centering
  \caption{Table of Abbreviations and Acronyms}
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l}
    \toprule
    \textbf{symbol} & \textbf{description}\\
    \midrule
    % TM & Theoretical Model\\
    accel & Accelerometer \\
    gyro & Gyroscope \\
    IMU & Inertial Measurement Unit\\
    mag & Magnetometer \\
    SRS & Software Requirements Specification\\
    VnV & Verification and Validation \\
    % MEMS & Micro-electromechanical System \\
    % NED & North-East-Down \\
    % WMM & World Magnetic Model. \\
    \bottomrule
\end{tabular}\\
\label{tab:abb}
\end{table}

\wss{symbols, abbreviations, or acronyms --- you can simply reference the SRS \citep{SRS} tables, if
  appropriate}

\wss{Remove this section if it isn't needed}

\newpage

\pagenumbering{arabic}

\section{Introduction}

A Verification and Validation (VnV) plan is a document that describes the objectives, scope,
methods, and criteria for verifying and validating a software product. Verification is the process
of checking whether the software meets the specified requirements and design specifications.
Validation is the process of checking whether the software meets the user's needs and expectations.
A VnV plan helps to ensure the quality, reliability, and functionality of the software, as well as
to identify and correct any defects or errors before the software is released or deployed.


This document details the plan for verification and validation of \progname{}. Section
\ref{sec:general} provides an overview and objectives of this document. Section \ref{sec:plan}
discusses the methods of achieving the objectives. Section \ref{sec:system_test} covers the test
descriptions.

\wss{provide an introductory blurb and roadmap of the Verification and Validation plan}

\section{General Information} \label{sec:general}

This section will provide the background and objectives for this document.

\subsection{Summary}

\progname{} is an IMU-based attitude estimation algorithm. It consumes sensor data and produces an
estimate of the current orientation of the sensor relative to the Earth.

\wss{Say what software is being tested.  Give its name and a brief overview of its general
  functions.}

\subsection{Objectives}

The objectives of this Verification and Validation plan are the following:

\begin{itemize}
    \item Build confidence in the software correctness.
    \item Demonstrate the software's ability to accurately estimate orientation.
\end{itemize}

\wss{State what is intended to be accomplished.  The objective will be around the qualities that are
  most important for your project.  You might have something like: ``build confidence in the
  software correctness,'' ``demonstrate adequate understandability.'' etc.  You won't list all the
  qualities, just those that are most important.}

\noindent
Objectives that are not included in the scope of this document:

\begin{itemize}
    \item Demonstration of adequate understandability.
    \item Verification of external libraries.
\end{itemize}

It will be assumed that the documentation of \progname{} is adequate to facilitate sufficient
understandability for developers wishing to use it. Furthermore, it is assumed that external
libraries have been independently verified and validated.


\wss{You should also list the objectives that are out of scope.  You don't have the resources to do
everything, so what will you be leaving out.  For instance, if you are not going to verify the
quality of understandability, state this.  It is also worthwhile to justify why the objectives are
left out.}

\wss{The objectives are important because they highlight that you are aware of limitations in your
resources for verification and validation.  You can't do everything, so what are you going to
prioritize?  As an example, if your system depends on an external library, you can explicitly state
that you will assume that external library has already been verified by its implementation team.}

\subsection{Relevant Documentation}

\wss{Reference relevant documentation.  This will definitely include your SRS and your other project
  documents (design documents, like MG, MIS, etc).  You can include these even before they are
  written, since by the time the project is done, they will be written.}

See the Software Requirements Specification \citep{SRS} for \progname{}, it details the goals,
requirements, assumptions, and theory of the software. The
\href{https://github.com/adrian-soch/attitude_check/blob/main/docs/Design/SoftArchitecture/MG.pdf}{MG}
and
\href{https://github.com/adrian-soch/attitude_check/blob/main/docs/Design/SoftDetailedDes/MIS.pdf}{MIS}
document the design of \progname{}.

Further reading about attitude estimation can be found at \citep{madgwick_ecient_nodate}.
Information regarding evaluation of attitude estimation algorithms can be found at \citep{broad}.

\wss{Don't just list the other documents.  You should explain why they are relevant and how they
relate to your VnV efforts.}

\section{Plan} \label{sec:plan}

This section will detail the plan for the verification of the documentation and software for
\progname{}. The primary items that will be verified are: SRS, design, VnV, implementation.

\wss{Introduce this section.   You can provide a roadmap of the sections to come.}

% \subsection{Verification and Validation Team}

% \wss{Your teammates.  Maybe your supervisor. You should do more than list names.  You should say
%   what each person's role is for the project's verification.  A table is a good way to summarize
%   this information.}

\subsection{SRS Verification Plan}

The SRS \citep{SRS} will be verified via feedback from a domain expert and assigned secondary
reviewer. The following is a checklist for SRS review derived from \citep{wiegers2002peer}:

\begin{todolist}
    \item Are all internal cross-references to other requirements correct?
    \item Are all requirements written at a consistent and appropriate level of detail?
    \item Do any requirements conflict with or duplicate other requirements?
    \item Is each requirement written in clear, concise, unambiguous language?
    \item Is each requirement verifiable by testing, demonstration, review, or analysis?
    \item Are all requirements actually requirements, not design or implementation solutions?
\end{todolist}


\wss{List any approaches you intend to use for SRS verification.  This may include ad hoc feedback
  from reviewers, like your classmates, or you may plan for something more rigorous/systematic.}

\wss{Maybe create an SRS checklist?}

\subsection{Design Verification Plan}

To verify the design, feedback will be collected from domain expert and an assigned secondary
reviewer will use the following checklist:

\begin{todolist}
    \item Create a high-level diagram that represents the relationships between modules based on the
    Module Guide (MG) and Module Interface Specification (MIS) [to be cited]. This is intended to
    find gaps in the design.
    \item Confirm traceability matrices are complete.
    \item The uses diagram is a hierarchy.
    \item Spelling and grammar check.
    \item Low coupling between modules.
\end{todolist}

\wss{Plans for design verification}
\wss{The review will include reviews by your classmates}
\wss{Create a checklists?}

\subsection{Verification and Validation Plan Verification Plan}

This VnV plan will be verified via inspection from a domain expert and a secondary review. The
inspection will look for the following items:
\begin{todolist}
    \item Confirm all sections contain a verification checklist or description.
    \item Inspect system-level test cases for coverage of SRS requirements and goal statements, via
    traceability matrices.
    \item Inspect all test cases for complete definitions.
\end{todolist}

\wss{The verification and validation plan is an artifact that should also be verified.  Techniques
for this include review and mutation testing.}
\wss{The review will include reviews by your classmates}
\wss{Create a checklists?}

\subsection{Implementation Verification Plan}

A combination of static and dynamic tests will be used to verify \progname{}. Cppcheck
\citep{cppcheck} is a static code checking tool that will be employed to analyze the code for
undefined behaviour and poor design constructs.

System and unit level tests will be used to dynamically verify \progname{}. Section
\ref{sec:system_test} outlines the system-level tests. Section \ref{sec:unit_test} details the unit
tests.

\wss{You should at least point to the tests listed in this document and the unit testing plan.}
\wss{In this section you would also give any details of any plans for static verification of the
  implementation.  Potential techniques include code walkthroughs, code inspection, static
  analyzers, etc.}

\subsection{Automated Testing and Verification Tools}

\begin{itemize}
    \item Cmake \citep{cmake} is a build system tool that will be used to simplify building and
    testing.
    \item GoogleTest is a unit testing framework that support C++ code. It also includes a mocking
    framework. See \url{https://github.com/google/googletest}.
    \item GCOV, LCOV are tools for calculating and displaying unit test coverage metrics.
    \item Uncrustify is a tool that applies code formatting rules based on a configuration file. It
    will be used before every commit to the repo.
    \item GitHub PR checklists will help reviewers/developers see and check that all rules and tests
    are completed before code is merged into a protected branch (i.e. main).
    \item GitHub CI workflow will automate regression tests and checks that \progname{} builds are
    passing before a code is merged into a protected branch.
\end{itemize}

\wss{What tools are you using for automated testing.  Likely a unit testing framework and maybe a
  profiling tool, like ValGrind.  Other possible tools include a static analyzer, make, continuous
  integration tools, test coverage tools, etc.  Explain your plans for summarizing code coverage
  metrics. Linters are another important class of tools.  For the programming language you select,
  you should look at the available linters.  There may also be tools that verify that coding
  standards have been respected, like flake9 for Python.}

\wss{If you have already done this in the development plan, you can point to that document.}

\wss{The details of this section will likely evolve as you get closer to the implementation.}

\subsection{Software Validation Plan}

For the scope of this project, software validation will consist of benchmarking against existing
algorithms. The \% difference of the Root Mean Squared Error (RMSE) of \progname{} and
\href{https://ahrs.readthedocs.io/en/latest/filters/madgwick.html}{AHRS} should be $\leq \epsilon$.
The data will come from the BROAD dataset \citep{broad}. The derivation of RMSE can be found in the Section \ref{sec:calc}.

\wss{If there is any external data that can be used for validation, you should point to it here.  If
  there are no plans for validation, you should state that here.} \wss{You might want to use review
  sessions with the stakeholder to check that the requirements document captures the right
  requirements.  Maybe task based inspection?} \wss{For teams without an external supervisor, user
  testing can serve the same purpose as a Rev 0 demo for the supervisor.}
\wss{This section might reference back to the SRS verification section.}

\section{System Test} \label{sec:system_test}

\subsection{Tests for Functional Requirements}

\wss{Subsets of the tests may be in related, so this section is divided into different areas.  If
  there are no identifiable subsets for the tests, this level of document structure can be removed.}
  \wss{Include a blurb here to explain why the subsections below cover the requirements.  References
  to the SRS would be good here.}

\subsubsection{Inputs and Outputs}

This section covers requirements R1 and R4 of the SRS. This includes the input and output
requirements for \progname{}. For input constraints see Section 4.2.8 of the
\href{https://github.com/adrian-soch/attitude_check/blob/main/docs/SRS/SRS.pdf}{SRS}.

\wss{It would be nice to have a blurb here to explain why the subsections below cover the
  requirements.  References to the SRS would be good here.  If a section covers tests for input
  constraints, you should reference the data constraints table in the SRS.}

% \paragraph{Title for Test}

\begin{enumerate}

\item[\refstepcounter{testnum} \Tthetestnum \label{t:sys_io}:] \textbf{Input/Output Test} \\


    \textbf{Control:} Automatic

    \textbf{Initial State:} Uninitialized

    \begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
    Step & Input & Output \\ \hline
    1 &
        \begin{tabular}[c]{@{}l@{}}Initialize with: $ \Delta t = 1.0,{}^E\mathbf{b} = [1.0, 1.0,
        1.0],$ \\ $\gamma = 0.6, \text{outputType} = \text{Quat} $ \end{tabular} &
        \begin{tabular}[c]{@{}l@{}l@{}}Assert ``get params" method equals\\ $ \Delta t =
        1.0,{}^E\mathbf{b} = [1.0, 1.0, 1.0],$ \\ $\gamma = 0.6, \text{outputType} = \text{Quat}
        $\end{tabular} \\ \hline
    2 &
        \begin{tabular}[c]{@{}l@{}l@{}}Call ``update" with: \\${}^S\mathbf{a}_t = [0,0,9.81], \quad$
          ${}^S\mathbf{\bm{\omega}}_t = [0,0,0]$ \\ ${}^S\mathbf{m}_t = [16676.8, -3050.9, 49916.9]$
          \end{tabular} &
        \begin{tabular}[c]{@{}l@{}}Assert ``update" output is a \\ normalized quaternion $\in
        \mathbb{R}^4$. \end{tabular} \\ \hline
    3 &
    \begin{tabular}[c]{@{}l@{}}Initialize with: $ \Delta t = 1.0,{}^E\mathbf{b} = [1.0, 1.0, 1.0],$
      \\ $\gamma = 0.6, \text{outputType} = \text{Rot} $ \end{tabular} &
      \begin{tabular}[c]{@{}l@{}l@{}}Assert ``get params" method equals\\ $ \Delta t =
      1.0,{}^E\mathbf{b} = [1.0, 1.0, 1.0],$ \\ $\gamma = 0.6, \text{outputType} = \text{Rot}
      $\end{tabular} \\ \hline
    4 &
    \begin{tabular}[c]{@{}l@{}l@{}}Call ``update" with: \\${}^S\mathbf{a}_t = [0,0,9.81], \quad$
      ${}^S\mathbf{\bm{\omega}}_t = [0,0,0]$ \\ ${}^S\mathbf{m}_t = [16676.8, -3050.9, 49916.9]$
      \end{tabular} &
    \begin{tabular}[c]{@{}l@{}}Assert ``update" output is a \\ matrix $\in \mathbb{R}^{3 \times 3}$.
    \end{tabular} \\ \hline
    5 &
    \begin{tabular}[c]{@{}l@{}}Initialize with: $ \Delta t = 1.0,{}^E\mathbf{b} = [1.0, 1.0, 1.0],$
      \\ $\gamma = 0.6, \text{outputType} = \text{Euler} $ \end{tabular} &
      \begin{tabular}[c]{@{}l@{}l@{}}Assert ``get params" method equals\\ $ \Delta t =
      1.0,{}^E\mathbf{b} = [1.0, 1.0, 1.0],$ \\ $\gamma = 0.6, \text{outputType} = \text{Euler}
      $\end{tabular} \\ \hline
    6 &
    \begin{tabular}[c]{@{}l@{}l@{}}Call ``update" with: \\${}^S\mathbf{a}_t = [0,0,9.81], \quad$
      ${}^S\mathbf{\bm{\omega}}_t = [0,0,0]$ \\ ${}^S\mathbf{m}_t = [16676.8, -3050.9, 49916.9]$
      \end{tabular} &
    \begin{tabular}[c]{@{}l@{}}Assert ``update" output \\ is vector $\in \mathbb{R}^3$.
    \end{tabular} \\ \hline
    \end{tabular}
    \end{table}

    \textbf{Test Case Derivation:} N/A

    \textbf{How test will be performed:} At each step, apply the inputs and assert the output.

\end{enumerate}

\subsubsection{Calculations} \label{sec:calc} This section covers requirements R2 and R3 of the SRS.
This includes the input and output requirements for \progname{}. For input constraints see Section
4.2.8 of the \href{https://github.com/adrian-soch/attitude_check/blob/main/docs/SRS/SRS.pdf}{SRS}.

The accuracy metric is described in \cite{broad}, it defines the difference between two quaternions
(\ref{eqn:diff_quat}), the total error (\ref{eqn:error}), and the RMSE (\ref{eqn:rmse}):
\begin{align}
    \mathbf{q}_{e, t} =& {}^S_E\mathbf{q}^{*}_{gt, t}  {}^S_E\mathbf{q}_{est, t} = [q_w, q_x, q_y, q_z]^T \label{eqn:diff_quat} \\
    e_q =& 2 \arccos(|q_w|)  \label{eqn:error}\\
    \text{RMSE} =& \sqrt{\cfrac{\sum_{t=0}^n(e)^2}{n}}  \label{eqn:rmse}
\end{align}

see \cite{broad} for the symbol definitions and a full explanation. Often computing separate errors
for the heading and inclination components provides better insight into the performance. When
magnetometer data is not available, the header error will be much larger than the other sources of
error.

First the difference between the estimate and the ground truth must be expressed in the Earth frame
(\ref{eqn:diff_quat2}). The equation for the heading only error is defined in
(\ref{eqn:heading_err}) and the inclination only error is defined by (\ref{eqn:inc_error}):

\begin{align}
    {}^E \mathbf{q}_{e,t} =& {}^S_E\mathbf{q}_{est, t} {}^S_E\mathbf{q}^{*}_{gt, t} = [q_w, q_x, q_y, q_z]^T \label{eqn:diff_quat2} \\
    e_{h} =& 2 \arctan(|\cfrac{q_z}{q_w}|) \label{eqn:heading_err} \\
    e_{i} =&  2 \arccos(\sqrt{q_w^2 + q_z^2}) \label{eqn:inc_error}
\end{align}

\textbf{Note:} Ground truth quaternions and their corresponding sensor measurements are provided in
the Appendix \ref{sec:imu_data} in Tables \ref{tab:gt_data} and \ref{tab:gt_label}, however the
tester should use the full dataset found in \citep{broad_code}.

\begin{enumerate}

\item[\refstepcounter{testnum} \Tthetestnum \label{t:sys_calc_mag}:] \textbf{Orientation with
Magnetometer} \\

    \textbf{Control:} Automatic

    \textbf{Initial State:} Uninitialized

    \begin{table}[H]
        \centering
        \begin{tabular}{|l|l|l|}
        \hline
        Step & Input & Output \\ \hline
        1    & \begin{tabular}[c]{@{}l@{}l@{}}Initialize with: $ \Delta t = 10.0, \gamma = 0.6,$ \\$
        {}^E\mathbf{b} = [16676.8, -3050.9, 49916.9],$\\ $\text{outputType} = \text{Quat} $
        \end{tabular} & - \\ \hline
        2 & \begin{tabular}[c]{@{}l@{}}Call ``update" and loop through \\ measurements in Table
        \ref{tab:gt_data} \end{tabular} & Assert quaternion magnitude is 1.     \\ \hline
        3 & \begin{tabular}[c]{@{}l@{}}Calculate RMSE of $e_i$ for
          \href{https://ahrs.readthedocs.io/en/latest/filters/madgwick.html}{AHRS}\\and \progname{}
          using table \ref{tab:gt_label}\end{tabular}             &
          \begin{tabular}[c]{@{}l@{}}Assert that the \% difference between \\ methods $\leq
          \epsilon$.\end{tabular} \\ \hline
        \end{tabular}
        \end{table}

    \textbf{Test Case Derivation:} Benchmark dataset with labelled ground truth orientation for each
    set of sensor measurements from \citep{broad_code}.

    \textbf{How test will be performed:} At each step, apply the inputs and assert the output.

\item[\refstepcounter{testnum} \Tthetestnum \label{t:sys_calc_no_mag}:] \textbf{Orientation without
Magnetometer}\\

    \textbf{Control:} Automatic

    \textbf{Initial State:} Uninitialized

    \begin{table}[H]
        \centering
        \begin{tabular}{|l|l|l|}
        \hline
        Step & Input & Output \\ \hline
        1    & \begin{tabular}[c]{@{}l@{}l@{}}Initialize with: $ \Delta t = 10.0, \gamma = 0.6,$ \\$
        {}^E\mathbf{b} = [16676.8, -3050.9, 49916.9],$\\ $\text{outputType} = \text{Quat} $
        \end{tabular} & - \\ \hline
        2 & \begin{tabular}[c]{@{}l@{}}Call ``update" and loop through \\ \{accel, gyro\}
        measurements in Table \ref{tab:gt_data} \end{tabular} & Assert output quat is normalized \\
        \hline
        3 & \begin{tabular}[c]{@{}l@{}}Calculate RMSE of $e_i$ for
            \href{https://ahrs.readthedocs.io/en/latest/filters/madgwick.html}{AHRS}\\and
            \progname{} using table \ref{tab:gt_label}\end{tabular}             &
            \begin{tabular}[c]{@{}l@{}}Assert that the \% difference between \\ methods $\leq
            \epsilon$.\end{tabular} \\ \hline
        \end{tabular}
        \end{table}

    \textbf{Test Case Derivation:} Benchmark dataset with labelled ground truth orientation for each
    set of sensor measurements from \citep{broad_code}.

    \textbf{How test will be performed:} At each step, apply the inputs and assert the output.

    \textbf{Note:} Only Pitch and Roll components are evaluated.

\end{enumerate}


\subsection{Tests for Nonfunctional Requirements}

\wss{The nonfunctional requirements for accuracy will likely just reference the appropriate
  functional tests from above.  The test cases should mention reporting the relative error for these
  tests.  Not all projects will necessarily have nonfunctional requirements related to accuracy}

\wss{Tests related to understandability could include conducting a understandability test and
  survey.  The survey will be in the Appendix.}

\wss{Static tests, review, inspections, and walkthroughs, will not follow the format for the tests
given below.}

\subsubsection{Accuracy}

% \paragraph{Title for Test}

\begin{enumerate}

\item[\refstepcounter{testnum} \Tthetestnum \label{t:a1}:] \textbf{test-a1} \\

    Type: Manual

    This test refers to Section \ref{sec:calc}. The accuracy test will be conducted when changes to
    the logic or calculation components of the program are made. See \url{https://github.com/adrian-soch/attitude_check/blob/main/scripts/compare_results.py}.
\end{enumerate}

\subsubsection{Understandability}

\begin{enumerate}

\item[\refstepcounter{testnum} \Tthetestnum \label{t:u1}:] \textbf{test-u1} \\

    Type: Manual

    Initial State: N/A

    Input/Condition: N/A

    Output/Result: Successful integration of \progname{} into a project. This represents how typical
    users interact with the software.

    How test will be performed: A manual inspection of the code, specifically the header file. Is
    each input documented/commented? This test passes if this is true.
\end{enumerate}

\subsubsection{Maintainability}

\begin{enumerate}

\item[\refstepcounter{testnum} \Tthetestnum \label{t:m1}:] \textbf{test-m1} \\

    Type: Manual

    Initial State: N/A

    Input/Condition: N/A

    Output/Result: Successful addition of a likely change within the threshold defined in NFR3 of
    the SRS.

    How test will be performed: If a likely change needs to be added, measure the development time
    and compare it to the total development time. If it is less than the threshold specified in the
    SRS, this test passes.

    This test will not be explicitly conducted.
\end{enumerate}

\subsubsection{Portability}

\begin{enumerate}

\item[\refstepcounter{testnum} \Tthetestnum \label{t:p1}:] \textbf{test-p1} \\

    Type: Manual

    Initial State: N/A

    Input/Condition: One set of initialization inputs, 1 set of measurements

    Output/Result: Result of compilation and execution.

    How test will be performed: Build the project on Ubuntu and MacOS. Build and execute \progname{}
    on a microcontroller with an IMU/MARg sensor.
\end{enumerate}

\subsection{Traceability Between Test Cases and Requirements}

\begin{table}[!h]
    \centering
    \caption{Relation of Test Cases and Requirements.}
    \label{tab:traceability}
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|}
    \hline
      & R1 & R2 & R3 & R4 & NFR1 & NFR2 & NFR3 & NFR4 \\ \hline
    \testref{t:sys_io} & X  &    &    & X  &      &      &      &      \\ \hline
    \testref{t:sys_calc_mag} &    & X  &    &    & X    &      &      &      \\ \hline
    \testref{t:sys_calc_no_mag} &    &    & X  &    & X    &      &      &      \\ \hline
    \testref{t:a1} &    &    &    &    & X    &      &      &      \\ \hline
    \testref{t:u1} &    &    &    &    &      & X    &      &      \\ \hline
    \testref{t:m1} &    &    &    &    &      &      & X    &      \\ \hline
    \testref{t:p1} &    &    &    &    &      &      &      & X    \\ \hline
    \end{tabular}
    \end{table}

\wss{Provide a table that shows which test cases are supporting which requirements.}

\section{Unit Test} \label{sec:unit_test}

This section provides details on the white box unit testing for \progname{}.

\subsection{Unit Testing Scope}

The scope of the unit tests will not include testing the matrix math functionality of the Eigen
library.

\subsection{Tests for Functional Requirements}

The tests for each module will be detailed here, each test will be part of an automated unit test
suite.

\subsubsection{Quaternion Module}

This module contributes to R1, R2, R3, and R4. Tests can be found in
\href{https://github.com/adrian-soch/attitude_check/blob/main/test/quaternion_test.cpp}{quaternion\_test.cpp}
The test names are related to the function that it tests. The tests are self documenting, since the
assertions and expected values are explicitly coded. Some tests are repeated for single and double
precision floating point values.

\begin{enumerate}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Invalid initialization}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Conjugate}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Product}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Norm}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Scalar product}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Subtract}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Add}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Subtract Equals}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Equals}
\end{enumerate}

\subsubsection{Utilities Module}

This module contributes to R2. Tests can be found in
\href{https://github.com/adrian-soch/attitude_check/blob/main/test/utilities_test.cpp}{utilities\_test.cpp}
The test names are related to the function that it tests. The tests are self documenting, since the
assertions and expected values are explicitly coded.

\begin{enumerate}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Euler to quat (double)}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Euler to quat (float)}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Rotation Matrix to quat (double)}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Rotation Matrix to quat (single)}
\end{enumerate}

\subsubsection{Initializers Module}

This module contributes to R2. Tests can be found in
\href{https://github.com/adrian-soch/attitude_check/blob/main/test/initializers_test.cpp}{initializers\_test.cpp}
The test names are related to the function that it tests. The tests are self documenting, since the
assertions and expected values are explicitly coded.

\begin{enumerate}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Accel to quat}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Mag to quat}
\end{enumerate}

\subsubsection{Attitude Check Module}

This module contributes to R1, R2, R3, R4, and R5. Tests can be found in
\href{https://github.com/adrian-soch/attitude_check/blob/main/test/attitude_check_test.cpp}{attitude\_check\_test.cpp}
The test names are related to the function that it tests. The tests are self documenting, since the
assertions and expected values are explicitly coded.

\begin{enumerate}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Invalid Initialization}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Invalid call to update}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Call with zero mag vector}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Call with zero gyro vector}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Call with zero acc vector}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Set quaternion}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Set gain}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Get gain}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Get Initial orientation}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Check MARG calculation}
  \item[\refstepcounter{utestnum} \UTthetestnum:] \textbf{Check IMU calculation}
\end{enumerate}

\subsection{Tests for Nonfunctional Requirements}

There are no unit tests for nonfunctional requirement.

\subsection{Traceability Between Test Cases and Modules}

\begin{table}[h]
  \centering
  \caption{Traceability Between Test Cases and Modules}
  \vspace{3mm}
  \label{tab:my-table}
  \begin{tabular}{l|c}
  Module         & Tests \\ \hline
  Quaternion     & UT1 - UT9      \\
  Matrix Math    &  None     \\
  Utilities      &   UT10 - UT13    \\
  Initializers   &  UT14 - UT15     \\
  Attitude Check &    UT16 - UT 26
  \end{tabular}
  \end{table}

\wss{Provide evidence that all of the modules have been considered.}

\newpage
\bibliographystyle{plainnat}

\bibliography{../refs/References, ../refs/bib}

\newpage

\section{Appendix}

% This is where you can place additional information.

\subsection{Symbolic Parameters}

The definition of the test cases will call for SYMBOLIC\_CONSTANTS. Their values are defined in this
section for easy maintenance.

\begin{table}[h]
    \centering
    \begin{tabular}{|l|l|}
    \hline
    \textbf{Param} & \textbf{Value} \\ \hline
    $\epsilon$     &      3 \%          \\ \hline
    \end{tabular}
    \end{table}

% \subsection{Understandability Survey Questions?}

% \wss{This is a section that would be appropriate for some projects.}

% \newpage{} \section*{Appendix --- Reflection}

% The information in this section will be used to evaluate the team members on the graduate
% attribute of Lifelong Learning.  Please answer the following questions:

\subsection{IMU Test Data} \label{sec:imu_data}

\begin{landscape}
\begin{table}[]
\caption{Sample of ground truth quaternion.}
\label{tab:gt_label}
% \small
\centering
\begin{tabular}{|l||l|l|l|l|} \hline
$t$ & $q_w$ & $q_x$ & $q_y$ & $q_z$ \\ \hline
\hline
0&0.999926 & 0.001208 & -0.002004 & -0.011972 \\ \hline
1&0.999923 & 0.001884 & -0.002375 & -0.012036 \\\hline
2&0.999922 & 0.002302 & -0.002478 & -0.012057 \\\hline
3&0.999925 & 0.002024 & -0.001862 & -0.011960 \\\hline
4&0.999927 & 0.001747 & -0.001245 & -0.011863 \\\hline
5&0.999927 & 0.001672 & -0.001145 & -0.011925 \\\hline
6&0.999926 & 0.001621 & -0.001108 & -0.012006 \\\hline
7&0.999926 & 0.001454 & -0.001265 & -0.012036 \\\hline
8&0.999926 & 0.001176 & -0.001609 & -0.012017 \\\hline
9&0.999926 & 0.001012 & -0.001949 & -0.012006 \\ \hline
\end{tabular}
\end{table}

\begin{table}[]
    \centering
    \caption{Sample of sequential sensor measurements}
    % \footnotesize
    \label{tab:gt_data}
    \begin{tabular}{|l||l|l|l|l|l|l|l|l|l|}
    \hline
    {$t$} & {$\text{acc}_x$} & {$\text{acc}_y$} & {$\text{acc}_z$} & {$\text{gyro}_x$} &
    {$\text{gyro}_y$} & {$\text{gyro}_z$} & {$\text{mag}_x$} & {$\text{mag}_y$} & {$\text{mag}_z$}
    \\ \hline \hline
    0 & 0.090941 & -0.031273 & 9.759028 & 0.005327 & -0.000000 & -0.004260 & 0.554144  & 14.948225 &
    -41.506577 \\ \hline
    1 & 0.130181 & -0.001843 & 9.793363 & 0.005327 & 0.001065  & -0.008522 & 0.035031  & 15.327949 &
    -41.656347 \\ \hline
    2 & 0.072302 & -0.006748 & 9.864976 & 0.003196 & 0.001065  & -0.007458 & -0.484083 & 15.707673 &
    -41.806118 \\ \hline
    3 & 0.062492 & 0.002081  & 9.855166 & 0.000000 & 0.002131  & -0.005327 & 0.183349  & 15.707673 &
    -40.982379 \\ \hline
    4 & 0.090941 & 0.069770  & 9.754123 & 0.005327 & 0.003196  & -0.001065 & 0.850781  & 15.707673 &
    -40.158640 \\ \hline
    5 & 0.077207 & 0.021701  & 9.735484 & 0.003196 & 0.002131  & -0.005327 & 0.850781  & 15.707673 &
    -40.158640 \\ \hline
    6 & 0.072302 & -0.112696 & 9.812002 & 0.003196 & 0.001065  & -0.004260 & 0.850781  & 15.707673 &
    -40.158640 \\ \hline
    7 & 0.115466 & 0.069770  & 9.893425 & 0.004260 & 0.001065  & -0.002131 & 0.183349  & 15.555783 &
    -40.308411 \\ \hline
    8 & 0.052682 & 0.021701  & 9.807097 & 0.001065 & 0.004260  & -0.003196 & -0.484083 & 15.403894 &
    -40.458182 \\ \hline
    9 & 0.029138 & 0.006986  & 9.816907 & 0.004260 & 0.001065  & -0.005327 & -0.261606 & 15.631728 &
    -41.057264 \\ \hline
    \end{tabular}
    \end{table}
\end{landscape}


\end{document}
